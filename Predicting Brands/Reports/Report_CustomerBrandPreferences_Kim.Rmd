---
title: "Customer Brand Preferences"
author: "KimN"
date: "17 10 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



In the following, we will evaluate the brand preferences of BlackwellÂ´s customers using:

1. PLS Analysis
  + 1.1 Training and testing the model
  + 1.2 Brand Predictions

2. Decision Tree
  + 2.1 Training and testing the model
  + 2.2 Brand Predictions
  
3. Random Forest Analysis
  + 3.1 Training and testing the model
  + 3.2 Brand Predictions


But first, we will load the data and all neccessary libraries

### Loading data sets and libraries

```{r loading data, echo = TRUE, message=FALSE}

BelkinElagoComplete <- 
  read.delim("C:/Users/kimne/Ubiqum/Module2/BelkinElagoComplete.csv")

SurveyIncomplete <- 
  read.csv("C:/Users/kimne/Ubiqum/Module2/BrandPreferences/Data/SurveyIncomplete.csv")

BelkinData <- BelkinElagoComplete


library(caret)
library(mlbench)
library(dplyr)
library(C50)
library(entropy)
library(funModeling)
```


### Renaming attributes

```{r naming}
names(BelkinData) <- 
  c("salary","age","education","car","zip","credit","brand")

names(SurveyIncomplete) <- 
  c("salary","age","education","car","zip","credit","brand")
```


### Selecting subset of arrtributes, pre-processing

```{r pre-processing}
BelkinSmall <- BelkinData %>% select("salary","age","education","brand")

Incomplete <- SurveyIncomplete %>% select("salary","age","education","brand")
```

```{r factoring, eval = FALSE}
as.factor(BelkinSmall$brand)

as.factor(BelkinSmall$education)

as.factor(Incomplete$education)

testing$brand <- as.factor(testing$brand)
```

### Data splitting

```{r data-splitting}
inTrain <- createDataPartition(y=BelkinSmall$brand, 
                               p=0.75, list=FALSE)
str(inTrain)

training <- BelkinSmall[inTrain,]

testing <- BelkinSmall[-inTrain,]
```



# 1. Partial Least Squares Analysis
# 1.1 Training and testing the model


### PLS Model using 10 fold cross-validation

```{r PLS Model}
ctrl <- trainControl(method = "repeatedcv", 
                     number = 10,
                     repeats = 3)

plsFit <- train(brand~., data=training, 
                method="pls", 
                preProc=c("center","scale"),
                tuneLength = 4,
                trControl=ctrl)
plsFit

ggplot(plsFit) +
  ggtitle("PLS Model using CV with k=10 and Accuracy") +
  xlab("Number of Parameters")
```

### PLS model using Metric = ROC

```{r PLS Model with ROC}
ctrl <- trainControl(method = "repeatedcv", 
                     repeats = 3,
                     number = 10,
                     classProbs=TRUE, 
                     summaryFunction=twoClassSummary)

plsFit <- train(brand~., data=training, 
                method="pls", 
                preProc=c("center","scale"),
                tuneLength = 4,
                trControl=ctrl, 
                metric="ROC")

plsFit

ggplot(plsFit) +
  ggtitle("PLS Model using CV with k=10 and ROC metric") +
  xlab("Number of Parameters")
```


### Importance of variables

```{r var imp}
varImp(plsFit)
```

### Prediction Model

```{r prediction PLS}
plsPred <- predict(plsFit, newdata = testing)

testing$brand_pred <- predict(plsFit, testing)

#postResample(plsPred, testing$brand)

summary(plsPred)
```

### Confusion Metrix

```{r confusion metrix PLS}
cmPls <- confusionMatrix(plsPred, testing$brand)

print(cmPls)
```

### Entropy and Info Gain

```{r entropy}
entropy_2(BelkinData$education,BelkinData$brand)

ggplot(BelkinData, aes(education, fill = brand)) + geom_bar()


entropy(BelkinData$salary,method="ML")

entropy(BelkinData$age,method="ML")

entropy(BelkinData$education,method="ML")
```



# 1.2 Brand Prediction - PLS


### Applying the trained PLS Model to make prediction

```{r PLS Model final}
ctrl <- trainControl(method = "repeatedcv", 
                     number = 10,
                     repeats = 3)

plsFit <- train(brand~., data=BelkinSmall, 
                method="pls", 
                preProc=c("center","scale"),
                tuneLength = 4,
                trControl=ctrl)
plsFit

ggplot(plsFit) +
  ggtitle("PLS Model using CV with k=10 and Accuracy - Brand Predictions") +
  xlab("Number of Parameters")
```

## Applying the trained PLS model using ROC for predictions

```{r PLS Model with ROC final}
ctrl <- trainControl(method = "repeatedcv", 
                     repeats = 3,
                     number = 10,
                     classProbs=TRUE, 
                     summaryFunction=twoClassSummary)

plsFit <- train(brand~., data=BelkinSmall, 
                method="pls", 
                preProc=c("center","scale"),
                tuneLength = 4,
                trControl=ctrl, 
                metric="ROC")

plsFit


ggplot(plsFit) +
  ggtitle("PLS Model using CV with k=10 and ROC metric - Brand Predictions") +
  xlab("Number of Parameters")
```


### Brand Prediction Model with PLS

```{r prediction final PLS}
plsPred <- predict(plsFit, newdata = Incomplete)

Incomplete$brand_Pred <- predict(plsFit, Incomplete)
```

```{r prediction results PLS}
summary(plsPred)

ggplot(Incomplete, aes(Incomplete$brand_Pred)) + geom_bar()
```



# 2. Decision Tree
# 2.1 Training and testing the model


### Decision Tree Model

```{r decisionTree Model}
vars <- c("age","education","salary")

c50Fit <- C5.0(x = training[,vars], 
               y = training$brand,
               tuneLength = 4,
               trial = 4,
               mtry = 2,
               control = C5.0Control())

summary(c50Fit)

plot(c50Fit, main="Decision Tree")

table(predict(c50Fit,testing[,vars]))
```


### Making predictions based on the trained Model

```{r tree prediction}
c50Pred <- predict(c50Fit, 
                   newdata = testing)

c50Pred <- predict(c50Fit, 
                    newdata = testing,
                    type="prob")

c50Pred <- predict(c50Fit, 
                    newdata = testing,
                    type="class")
```

### Importance of variables - Decision Tree

```{r variable importancefor tree}
C5imp(c50Fit, metric="splits")
```

### Confusion Metrix - Decision Tree

```{r confusion metrix tree}
confusionMatrix(c50Pred, testing$brand)
```



# 2.2 Brand Prediction - Decision Tree


### Training the Decision Tree Model

```{r decisionTree Model final}
vars <- c("age","education","salary")

c50Fit <- C5.0(x = BelkinSmall[,vars], 
               y = BelkinSmall$brand,
               tuneLength = 4,
               trial = 4,
               mtry = 2,
               control = C5.0Control())

summary(c50Fit)

plot(c50Fit, main="Decision Tree")

table(predict(c50Fit,BelkinSmall[,vars]))

```


### Final Predictions - Decision Tree

```{r tree prediction final}
c50Pred <- predict(c50Fit, 
                   newdata = Incomplete)

c50Pred <- predict(c50Fit, 
                    newdata = Incomplete,
                    type="prob")

c50Pred <- predict(c50Fit, 
                    newdata = Incomplete,
                    type="class")
```

```{r prediction results tree}
summary(c50Pred)

Incomplete$brand_Pred <- predict(rfFit, Incomplete)

ggplot(Incomplete, aes(Incomplete$brand_Pred)) + geom_bar(fill = "lightgreen")
```



# 3. Random Forest Analysis
# 3.1 Training and testing the model


### Random Forest Model using bagged trees, manually tuned

```{r rf model}
grid = expand.grid(.mtry = c(2,3)) 

ctrl <- trainControl(method = "oob" ,
                     search = "grid",
                     classProbs = TRUE
                     )

rfFit <- train(brand~., data=training, 
                method="rf", 
                preProc=c("center","scale"),
                tuneGrid = grid,
                trControl=ctrl
               )

rfFit

ggplot(rfFit) +
  ggtitle("Random Forest Model") +
  xlab("Number of Parameters")
```


### Importance of variables in RF Model

```{r var imp for rf}
varImp(rfFit)
```

### Prediction Model - Random Forest

```{r rf prediction}
rfPred <- predict(rfFit, newdata=testing, 
                   type="raw")  ## why raw? why does class not work ??

table(predict(rfFit))
```

### Confusion Metrix - Random Forest

```{r conf.metrix rf}
cmrf <- confusionMatrix(rfPred, testing$brand)

print(cmrf)
```



# 3.2 Brand Prediction - Random Forest


### Training the RF Model

```{r rf model final}
grid = expand.grid(.mtry = c(2,3)) 

ctrl <- trainControl(method = "oob" ,
                     search = "grid",
                     classProbs = TRUE
                     )

rfFit <- train(brand~., data=BelkinSmall, 
                method="rf", 
                preProc=c("center","scale"),
                tuneGrid = grid,
                trControl=ctrl
               )

rfFit

ggplot(rfFit) +
  ggtitle("Random Forest Model") +
  xlab("Number of Parameters")
```


### Final Predictions - Random Forest

```{r rf prediction final}
rfPred <- predict(rfFit, newdata=Incomplete, 
                   type="raw")  ## why raw? why does class not work ??

# what is wrong here?? postResample(rfFit, Incomplete$brand)

table((rfPred))

Incomplete$brand_Pred <- predict(rfFit, Incomplete)

ggplot(Incomplete, aes(Incomplete$brand_Pred)) + geom_bar(fill = "lightgreen")
```
